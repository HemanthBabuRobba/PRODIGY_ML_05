{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11959,"sourceType":"datasetVersion","datasetId":8544}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# import backend\nimport tensorflow as  tf\n\n# Model architecture\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, BatchNormalization\nfrom keras.layers import MaxPool2D, Activation, MaxPooling2D\n\n# model optimisation and scores\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import roc_auc_score, auc, roc_curve\n\n# Annealer\nfrom keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# Data processing\nfrom keras.utils import to_categorical\n\n#Custom data generator\nfrom tensorflow.keras.utils import Sequence\n\n#Save the model\nfrom tensorflow.keras.models import load_model\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport h5py\n\npolicy = tf.keras.mixed_precision.Policy('mixed_float16')\ntf.keras.mixed_precision.set_global_policy(policy)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-01T12:58:17.781749Z","iopub.execute_input":"2024-09-01T12:58:17.782065Z","iopub.status.idle":"2024-09-01T12:58:30.848155Z","shell.execute_reply.started":"2024-09-01T12:58:17.782037Z","shell.execute_reply":"2024-09-01T12:58:30.847162Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-09-01 12:58:20.313709: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-01 12:58:20.313876: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-01 12:58:20.443583: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/input/food-101/\nprint(\"Files in the input directory\")\nprint(os.listdir(\"food-101/food-101/meta\"))\n\n!head 'food-101/food-101/meta/classes.txt'\n!head 'food-101/food-101/meta/train.txt'\n!head 'food-101/food-101/meta/labels.txt'\n!head 'food-101/food-101/meta/test.txt'","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:58:56.126990Z","iopub.execute_input":"2024-09-01T12:58:56.127728Z","iopub.status.idle":"2024-09-01T12:59:00.292336Z","shell.execute_reply.started":"2024-09-01T12:58:56.127691Z","shell.execute_reply":"2024-09-01T12:59:00.291180Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/food-101\nFiles in the input directory\n['test.txt', 'train.json', 'labels.txt', 'test.json', 'train.txt', 'classes.txt']\napple_pie\nbaby_back_ribs\nbaklava\nbeef_carpaccio\nbeef_tartare\nbeet_salad\nbeignets\nbibimbap\nbread_pudding\nbreakfast_burrito\napple_pie/1005649\napple_pie/1014775\napple_pie/1026328\napple_pie/1028787\napple_pie/1043283\napple_pie/1050519\napple_pie/1057749\napple_pie/1057810\napple_pie/1072416\napple_pie/1074856\nApple pie\nBaby back ribs\nBaklava\nBeef carpaccio\nBeef tartare\nBeet salad\nBeignets\nBibimbap\nBread pudding\nBreakfast burrito\napple_pie/1011328\napple_pie/101251\napple_pie/1034399\napple_pie/103801\napple_pie/1038694\napple_pie/1047447\napple_pie/1068632\napple_pie/110043\napple_pie/1106961\napple_pie/1113017\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read the content of the 'classes.txt' file\nwith open('food-101/food-101/meta/classes.txt', 'r') as input_file:\n    lines = input_file.readlines()\n\n# Take the first 20 lines from the 'classes.txt' file\nfirst_20_lines = lines[:20]\n\n# Add the word \"other\" as the 21st line\nfirst_20_lines.append(\"other\\n\")\n\n# Write the modified content to the 'classes_mod.txt' file\nwith open('/kaggle/working/classes_mod.txt', 'w') as output_file:\n    output_file.writelines(first_20_lines)\n\nprint(\"Modified file 'classes_mod.txt' created successfully and here is the file:\")\ndf = pd.read_csv('/kaggle/working/classes_mod.txt', sep='\\t', header=None)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:59:05.172321Z","iopub.execute_input":"2024-09-01T12:59:05.173266Z","iopub.status.idle":"2024-09-01T12:59:05.194876Z","shell.execute_reply.started":"2024-09-01T12:59:05.173227Z","shell.execute_reply":"2024-09-01T12:59:05.193918Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Modified file 'classes_mod.txt' created successfully and here is the file:\n                     0\n0            apple_pie\n1       baby_back_ribs\n2              baklava\n3       beef_carpaccio\n4         beef_tartare\n5           beet_salad\n6             beignets\n7             bibimbap\n8        bread_pudding\n9    breakfast_burrito\n10          bruschetta\n11        caesar_salad\n12             cannoli\n13       caprese_salad\n14         carrot_cake\n15             ceviche\n16          cheesecake\n17        cheese_plate\n18       chicken_curry\n19  chicken_quesadilla\n20               other\n","output_type":"stream"}]},{"cell_type":"code","source":"############## First things first: Create a list of the image paths #############\ndef read_train_images_from_file(file_path, base_directory='food-101/food-101/images', image_extension='.jpg', num_lines=None):\n    with open(file_path, 'r') as file, open('/kaggle/working/sorted_full_paths.txt', 'w') as output_file:\n        lines = file.readlines()[:num_lines] if num_lines is not None else file.readlines()     \n        for line in lines:\n            image_path = line.strip()  # Remove leading/trailing whitespace\n            full_image_path = os.path.join(base_directory, image_path + image_extension)\n            #print('full_image_path',full_image_path)\n            output_file.write(full_image_path)\n            output_file.write(\"\\n\")\n            \ndef read_test_images_from_file(file_path, base_directory='food-101/food-101/images', image_extension='.jpg', num_lines=None):\n    with open(file_path, 'r') as file, open('/kaggle/working/test_full_paths.txt', 'w') as output_file:\n        lines = file.readlines()[:num_lines] if num_lines is not None else file.readlines()     \n        for line in lines:\n            image_path = line.strip()  # Remove leading/trailing whitespace\n            full_image_path = os.path.join(base_directory, image_path + image_extension)\n            #print('full_image_path',full_image_path)\n            output_file.write(full_image_path)\n            output_file.write(\"\\n\")            \n\n#read_images_from_file('food-101/food-101/meta/train.txt', num_lines=42)\nread_train_images_from_file('food-101/food-101/meta/train.txt')\nread_test_images_from_file('food-101/food-101/meta/test.txt')\nprint(\"sorted_full_paths.txt' created successfully and here is the file:\")","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:59:25.240870Z","iopub.execute_input":"2024-09-01T12:59:25.241237Z","iopub.status.idle":"2024-09-01T12:59:25.510767Z","shell.execute_reply.started":"2024-09-01T12:59:25.241210Z","shell.execute_reply":"2024-09-01T12:59:25.509759Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"sorted_full_paths.txt' created successfully and here is the file:\n","output_type":"stream"}]},{"cell_type":"code","source":"#from keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                    rotation_range=10,\n                                    width_shift_range=0.1,\n                                    height_shift_range=0.1,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True,\n                                    vertical_flip=True\n                                  )\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Read train image paths\nwith open('/kaggle/working/sorted_full_paths.txt', 'r') as file:\n    image_paths = file.read().splitlines()\n\n# Read train labels and process them\nwith open('/kaggle/working/train_mod.txt', 'r') as file:\n    labels = [line.split('/')[0].replace('_', ' ') for line in file]  # Remove underscores from labels\n\n# Create a train DataFrame\ndf_train = pd.DataFrame({'filename': image_paths, 'label': labels})\nprint(df_train)\n\ntrain_generator = train_datagen.flow_from_dataframe(dataframe=df_train, \n                                                   x_col='filename',\n                                                   y_col='label',  # If you have labels\n                                                   batch_size=100,\n                                                   class_mode='categorical')  # Change this according to your task\n\n# Read test image paths\nwith open('/kaggle/working/test_full_paths.txt', 'r') as file:\n    test_paths = file.read().splitlines()\n\n# Read test labels and process them\nwith open('/kaggle/working/test_mod.txt', 'r') as file:\n    test_labels = [line.split('/')[0].replace('_', ' ') for line in file]  # Remove underscores from labels\n\n# Create a test DataFrame\ndf_test = pd.DataFrame({'filename': test_paths, 'label': test_labels})\nprint(df_test)\n\ntest_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n                                                 x_col='filename',\n                                                 y_col='label',  # If you have labels\n                                                 batch_size=100,\n                                                 class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:00:46.710468Z","iopub.execute_input":"2024-09-01T13:00:46.710885Z","iopub.status.idle":"2024-09-01T13:05:48.386717Z","shell.execute_reply.started":"2024-09-01T13:00:46.710855Z","shell.execute_reply":"2024-09-01T13:05:48.385727Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"                                             filename      label\n0      food-101/food-101/images/apple_pie/1005649.jpg  apple pie\n1      food-101/food-101/images/apple_pie/1014775.jpg  apple pie\n2      food-101/food-101/images/apple_pie/1026328.jpg  apple pie\n3      food-101/food-101/images/apple_pie/1028787.jpg  apple pie\n4      food-101/food-101/images/apple_pie/1043283.jpg  apple pie\n...                                               ...        ...\n75745     food-101/food-101/images/waffles/981485.jpg      other\n75746      food-101/food-101/images/waffles/98238.jpg      other\n75747     food-101/food-101/images/waffles/982668.jpg      other\n75748     food-101/food-101/images/waffles/995085.jpg      other\n75749     food-101/food-101/images/waffles/999047.jpg      other\n\n[75750 rows x 2 columns]\nFound 75750 validated image filenames belonging to 21 classes.\n                                             filename      label\n0      food-101/food-101/images/apple_pie/1011328.jpg  apple pie\n1       food-101/food-101/images/apple_pie/101251.jpg  apple pie\n2      food-101/food-101/images/apple_pie/1034399.jpg  apple pie\n3       food-101/food-101/images/apple_pie/103801.jpg  apple pie\n4      food-101/food-101/images/apple_pie/1038694.jpg  apple pie\n...                                               ...        ...\n25245     food-101/food-101/images/waffles/942009.jpg      other\n25246     food-101/food-101/images/waffles/954028.jpg      other\n25247      food-101/food-101/images/waffles/96181.jpg      other\n25248      food-101/food-101/images/waffles/97015.jpg      other\n25249     food-101/food-101/images/waffles/971843.jpg      other\n\n[25250 rows x 2 columns]\nFound 25250 validated image filenames belonging to 21 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Two GPU Function\nstrategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n\nfrom keras.applications import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\n\n# Build your model here\nwith strategy.scope():\n    # Load the pre-trained model (excluding the top classification layers)\n    #base_model = VGG16(weights='imagenet', include_top=False, input_shape=(240, 320, 3))\n    base_model = VGG16(weights='imagenet', include_top=False)\n    \n    # Add custom classification layers\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(256, activation='relu')(x)\n    predictions = Dense(21, activation='softmax')(x)  # Assuming 21 classes\n\n    # Create the final model\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    # Freeze the layers from the pre-trained model (optional)\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Compile the model\n    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    # Add regularization (dropout)\n    model.add(Dropout(0.3))\n    \n    #Defining learning schedule    \n    from keras.callbacks import ReduceLROnPlateau\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n\n    \n    #Train the model using your custom data generator\n    model.fit(train_generator, epochs=20, callbacks=[reduce_lr], validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:11:27.382482Z","iopub.execute_input":"2024-09-01T13:11:27.383388Z","iopub.status.idle":"2024-09-01T13:11:29.538946Z","shell.execute_reply.started":"2024-09-01T13:11:27.383354Z","shell.execute_reply":"2024-09-01T13:11:29.537515Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number of devices: 2\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Add regularization (dropout)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.3\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/adam.py:60\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, name, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     45\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     59\u001b[0m ):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1 \u001b[38;5;241m=\u001b[39m beta_1\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2 \u001b[38;5;241m=\u001b[39m beta_2\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:19\u001b[0m, in \u001b[0;36mTFOptimizer.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:38\u001b[0m, in \u001b[0;36mBaseOptimizer.__init__\u001b[0;34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `decay` is no longer supported and will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument(s) not recognized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     name \u001b[38;5;241m=\u001b[39m auto_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Argument(s) not recognized: {'lr': 0.001}"],"ename":"ValueError","evalue":"Argument(s) not recognized: {'lr': 0.001}","output_type":"error"}]},{"cell_type":"code","source":"evaluation = model.evaluate(test_generator)\n\n# Save the model (optional)\nmodel.save(\"/kaggle/working/model.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:00:14.264514Z","iopub.status.idle":"2024-09-01T13:00:14.264892Z","shell.execute_reply.started":"2024-09-01T13:00:14.264727Z","shell.execute_reply":"2024-09-01T13:00:14.264742Z"},"trusted":true},"execution_count":null,"outputs":[]}]}